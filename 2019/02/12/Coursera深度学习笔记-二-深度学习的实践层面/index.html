<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">





















  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">


  <link rel="manifest" href="/images/manifest.json">


  <meta name="msapplication-config" content="/images/browserconfig.xml">





<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.0.1',
    sidebar: {"position":"left","display":"hide","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: true,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="机器学习的一些概念训练集、开发集、测试集(Train / Dev / Test sets)训练集——用于训练数据；开发集——又称”交叉验证集”，用于选择最好的模型；测试集——用于评估模型运行状况。 小数据集时，如只有100条，1000条，1万条数据，划分比例为：60%为训练集，20%为开发集，20%为测试集。 大数据集时，例如百万数据集时，98%为训练集，验证集和测试集各占1%。数据更多时，比例更">
<meta name="keywords" content="深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="Coursera深度学习笔记(二) - 深度学习的实践层面">
<meta property="og:url" content="https://wsczh.github.io/2019/02/12/Coursera深度学习笔记-二-深度学习的实践层面/index.html">
<meta property="og:site_name" content="Wangsc&#39;s Blog">
<meta property="og:description" content="机器学习的一些概念训练集、开发集、测试集(Train / Dev / Test sets)训练集——用于训练数据；开发集——又称”交叉验证集”，用于选择最好的模型；测试集——用于评估模型运行状况。 小数据集时，如只有100条，1000条，1万条数据，划分比例为：60%为训练集，20%为开发集，20%为测试集。 大数据集时，例如百万数据集时，98%为训练集，验证集和测试集各占1%。数据更多时，比例更">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://wangsc-blog.oss-cn-hangzhou.aliyuncs.com/DeepLearning/note2-1.png">
<meta property="og:updated_time" content="2019-03-24T09:02:32.360Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Coursera深度学习笔记(二) - 深度学习的实践层面">
<meta name="twitter:description" content="机器学习的一些概念训练集、开发集、测试集(Train / Dev / Test sets)训练集——用于训练数据；开发集——又称”交叉验证集”，用于选择最好的模型；测试集——用于评估模型运行状况。 小数据集时，如只有100条，1000条，1万条数据，划分比例为：60%为训练集，20%为开发集，20%为测试集。 大数据集时，例如百万数据集时，98%为训练集，验证集和测试集各占1%。数据更多时，比例更">
<meta name="twitter:image" content="http://wangsc-blog.oss-cn-hangzhou.aliyuncs.com/DeepLearning/note2-1.png">






  <link rel="canonical" href="https://wsczh.github.io/2019/02/12/Coursera深度学习笔记-二-深度学习的实践层面/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Coursera深度学习笔记(二) - 深度学习的实践层面 | Wangsc's Blog</title>
  




  <script async src="//www.googletagmanager.com/gtag/js?id=UA-136763172-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-136763172-1');
    }
  </script>



  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?1f36baabbf6dee7cc6b7446a41ec5607";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Wangsc's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Stay hungry, Stay foolish</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wsczh.github.io/2019/02/12/Coursera深度学习笔记-二-深度学习的实践层面/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wangsc">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wangsc's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Coursera深度学习笔记(二) - 深度学习的实践层面

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-02-12 08:54:16" itemprop="dateCreated datePublished" datetime="2019-02-12T08:54:16+08:00">2019-02-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-24 17:02:32" itemprop="dateModified" datetime="2019-03-24T17:02:32+08:00">2019-03-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="机器学习的一些概念"><a href="#机器学习的一些概念" class="headerlink" title="机器学习的一些概念"></a>机器学习的一些概念</h2><h3 id="训练集、开发集、测试集-Train-Dev-Test-sets"><a href="#训练集、开发集、测试集-Train-Dev-Test-sets" class="headerlink" title="训练集、开发集、测试集(Train / Dev / Test sets)"></a>训练集、开发集、测试集(Train / Dev / Test sets)</h3><p>训练集——用于训练数据；开发集——又称”交叉验证集”，用于选择最好的模型；测试集——用于评估模型运行状况。</p>
<p>小数据集时，如只有100条，1000条，1万条数据，划分比例为：60%为训练集，20%为开发集，20%为测试集。</p>
<p>大数据集时，例如百万数据集时，98%为训练集，验证集和测试集各占1%。数据更多时，比例更极端。</p>
<p>就算没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。</p>
<h3 id="偏差，方差（Bias-Variance）"><a href="#偏差，方差（Bias-Variance）" class="headerlink" title="偏差，方差（Bias /Variance）"></a>偏差，方差（Bias /Variance）</h3><p>高偏差——一般模型简单，未能很好拟合数据集，“欠拟合”；高方差——一般模型复杂，过度拟合数据集导致测试集拟合较差，“过拟合”。</p>
<p>举例，$(m,n)$代表$($训练集误差，开发集误差$)$，则：$(1\%,11\%)$为高方差，$(15\%,16\%)$为高偏差，$(15\%,30\%)$为高方差高偏差，$(0.5\%,1\%)$为低偏差低方差.</p>
<p>以下图举例，蓝色实直线(从左上直接到右下)为高偏差，紫色实线(从左上到右下，中间绕了下数据中异常的点)为高偏差高方差，蓝色虚线(左下角弧线)为低偏差低方差，xx线(图上没有，蓝色虚线并将异常点圈了进来)为高方差。<br><img src="http://wangsc-blog.oss-cn-hangzhou.aliyuncs.com/DeepLearning/note2-1.png" alt></p>
<p>高偏差或高方差的改进，针对神经网络：<br>高偏差——增加隐藏层个数，增加特征数，提高模型复杂程度，降低正则化程度；高方差——减少隐藏层数，减少特征数，降低模型复杂程度，增加训练集数据个数，增加正则化程度。</p>
<h2 id="对神经网络进行正则化"><a href="#对神经网络进行正则化" class="headerlink" title="对神经网络进行正则化"></a>对神经网络进行正则化</h2><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>一般情况下，加入正则化的代价函数如下：$J(w,b)=\frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m} || w ||_2^2$</p>
<p>$L2$正则化：$\frac{\lambda}{2m}||w||<em>2^2=\frac{\lambda}{2m}\sum</em>{j=1}^{n_x}w_j^2=\frac{\lambda}{2m}w^Tw$<br>$L1$正则化：$\frac{\lambda}{2m}||w||<em>1=\frac{\lambda}{2m}\sum</em>{j=1}^{n_x}|w_j|$<br>如果用的是$L1$正则化，$w$最终会是稀疏的，也就是说$w$向量中有很多0.</p>
<p>对于神经网络来讲：$J(w^{[1]},b^{[1]},…,w^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L || w^{l}||^2$<br>由于$w^{[l]}$是一个$(n^{[l]},n^{[l-1]})$维的矩阵，因此$||w^{[l]}||^2=\sum_{i=1}^{n^{[l-1]}}\sum_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^2$，这个矩阵的范数称为矩阵的“弗罗贝尼乌斯范数”，用下标$F$表示。</p>
<p>在反向传播中，$dW^{[l]} = {\frac{1}{m}}dz^{[l]}A^{[l-1]T}$，加入正则项后，$dW^{[l]} = {\frac{1}{m}}dz^{[l]}A^{[l-1]T}+\frac{\lambda}{m}w^{[l]}$，而对于$w^{[l]}:=w^{[l]}-\alpha dw^{[l]}$和之前一样。</p>
<h3 id="为什么正则化可以降低过拟合？"><a href="#为什么正则化可以降低过拟合？" class="headerlink" title="为什么正则化可以降低过拟合？"></a>为什么正则化可以降低过拟合？</h3><p>原因一：若$\lambda$设置的较大，为了使代价函数较小，$w$就会一定程度的变小。取个极端情况就是$w=0$，此时，神经网络中的部分节点可能就一直为0，相当于减少了特征数量，减少了复杂度，也就降低了过拟合情况。</p>
<p>原因二：假设激活函数选取tanh函数，当$w$在较小时，$z^{[l]}=w^{[l]}a^{[l-1]}+b^{[l]}$值会在0附近波动，此范围的tanh函数可以近似看成线性函数，神经网络也就相当于从复杂模型退化成为线性模型。</p>
<h3 id="Dropout-正则化"><a href="#Dropout-正则化" class="headerlink" title="Dropout 正则化"></a>Dropout 正则化</h3><p>该方法思路类似于硬币抛正反面，随机决定隐藏层节点的去留问题。一种常见的方法为——inverted dropout（反向随机失活）。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">layer = <span class="number">3</span></span><br><span class="line">keep-prob = <span class="number">0.8</span> <span class="comment">#保留下来的概率</span></span><br><span class="line">d3 = np.random.rand(a3.shape[<span class="number">0</span>],a3.shape[<span class="number">1</span>]) &lt; keep-prob</span><br><span class="line">a3 = np.mutiply(a3,d3)</span><br><span class="line">a3 = a3/keep-prob <span class="comment">#保证z4=w4a3+b4的期望值不变</span></span><br></pre></td></tr></table></figure>
<p>为什么最后除以保留概率？<br>由于删除矩阵中元素的概率为20%，因此$a^{[3]}$有20%元素被归零。而 $z^{[4]} = w^{[4]} a^{[3]} + b^{[4]}$，为了不影响$z^{[4]}$的期望值，需要用$w^{[4]} a^{[3]}/0.8$，它将会修正或弥补我们所需的那20%，$a^{[3]}$的期望值不会变，这就是所谓的dropout方法。</p>
<p>测试阶段并不使用dropout方法，因为在测试阶段进行预测时，我们不期望输出结果是随机的，如果测试阶段应用dropout函数，预测会受到干扰。</p>
<p>优点：对于神经网络来说，针对于容易出现过拟合情况的层，可以将keep-prob值设小一点；对于不会出现过拟合情况的层，可以将keep-prob值设为1。<br>缺点：代价函数不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。因此在计算代价函数时，保持所有层keep-prob值为1.</p>
<p>dropout是一种正则化方法，有助于预防过拟合，因此除非算法过拟合，不然一般不会使用dropout的。比如计算机视觉领域因为没有足够的数据，容易过拟合，才经常使用该方法。</p>
<h3 id="其他正则化方法"><a href="#其他正则化方法" class="headerlink" title="其他正则化方法"></a>其他正则化方法</h3><p>除了$L2$正则化和随机失活（dropout）正则化，还有几种方法可以减少神经网络中的过拟合:</p>
<p>一、数据扩增<br>如果数据扩增代价较高时，也可以对数据进行一定的变化生成新的数据。比如拟合猫咪图片分类器，我们可以通过对图片水平翻转、随意裁剪等等方法增加数据。</p>
<p>二、early stopping<br>运行梯度下降时，可以绘制训练误差或绘制代价函数的优化过程，在训练集上用0-1记录分类误差次数。而验证集误差通常会先呈下降趋势，然后在某个节点处开始上升，early stopping方法就是表示神经网络在当前节点已经表现很好，可以就此停止训练。</p>
<p>early stopping的主要缺点：无法处理代价函数不够小与出现过拟合问题之间的矛盾。提早停止梯度下降，代价函数可能不够小；反之，有可能出现过拟合。用一种方法同时解决两个问题，这样做的结果使得需要考虑的东西变得更复杂。</p>
<p>如果不用early stopping，而用$L2$正则化，训练神经网络的时间就可能很长。这导致超参数搜索空间更容易分解，也更容易搜索，但是缺点在于，你必须尝试很多正则化参数的值，这也导致搜索大量$\lambda$值的计算代价太高。</p>
<p>Early stopping的优点是，只运行一次梯度下降，你可以找出$w$的较小值，中间值和较大值，而无需尝试$L2$正则化超参数$\lambda$的很多值。</p>
<h2 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h2><h3 id="输入数据的归一化"><a href="#输入数据的归一化" class="headerlink" title="输入数据的归一化"></a>输入数据的归一化</h3><p>首先进行零均值化，$x:=x-\mu$。其中$\mu$为x的均值，计算方法为：$\mu = \frac{1}{m}\sum_{i=1}^mx^{(i)}$。<br>然后进行方差归一化，$x:=x/\sigma^2$。其中$\sigma$为x的方差，计算方法为：$\sigma^{2}= \frac{1}{m}\sum_{i=1}^{m}(x^{(i)})^{2}$。</p>
<p>归一化的好处可以加快梯度下降的过程，比未归一化的学习率可以稍微大一点。</p>
<h3 id="梯度消失与梯度爆炸"><a href="#梯度消失与梯度爆炸" class="headerlink" title="梯度消失与梯度爆炸"></a>梯度消失与梯度爆炸</h3><p>神经网络一般并不会太深，否则容易出现梯度消失与梯度爆炸情况。</p>
<p>假设一个神经网络模型中，激活函数为$g(z)=z$，参数$b^{[l]}=0$，则可以得到：$\hat{y} = W^{[L]}W^{[L-1]}W^{[L-2]}…W^{[3]}W^{[2]}W^{[1]}x$</p>
<p>假设每个权重矩阵$W^{[l]} = \begin{bmatrix} 1.5 &amp; 0 \\ 0 &amp; 1.5 \end{bmatrix}$，则有$\hat{y}= W^{[1]}W\begin{bmatrix} 1.5 &amp; 0 \\ 0 &amp; 1.5 \end{bmatrix}^{(L -1)}x$，即$\hat{y} = 1.5^{(L-1)}x$。可以看出对于深层神经网络来说，$\hat{y}$将呈现爆炸式增长。</p>
<p>类似，若$W^{[l]} = \begin{bmatrix} 0.5&amp; 0 \\ 0 &amp; 0.5  \end{bmatrix}$，则对于深层神经网络来说，$\hat{y}$将呈现指数级递减。</p>
<h3 id="神经网络的权重初始化"><a href="#神经网络的权重初始化" class="headerlink" title="神经网络的权重初始化"></a>神经网络的权重初始化</h3><p>假定一个神经网络只有一个神经元，该神经元有n个输入特征，，从$x_{1}$到$x_{n}$，经过$a=g(z)$处理，最终得到$\hat{y}$。</p>
<p>$z = w_{1}x_{1} + w_{2}x_{2} + \ldots +w_{n}x_{n}$，$b=0$，暂时忽略$b$。当$n$越大，为了防止$z$值过大或过小，希望$w_{i}$越小，因为$z$是$w_{i}x_{i}$的和，最合理的方法就是设置$w_{i}=\frac{1}{n}$，$n$表示神经元的输入特征数量。实际上要做的就是设置某层权重矩阵如下，其中$n^{[l - 1]}$是第$l$层的输入特征数（即第$l-1$层神经元数量）。</p>
<p>$w^{[l]} = np.random.randn( \text{shape})*\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]}})$</p>
<p>如果用Relu激活函数，用这个公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]}})$会更好。<br>如果使用tanh函数，可以用公式$\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]}})$会更好。</p>
<h3 id="梯度检验"><a href="#梯度检验" class="headerlink" title="梯度检验"></a>梯度检验</h3><p>为了验证后向传播是否正确实施，有时候会进行梯度检验。方法为根据导数的定义求代价函数在当前点的导数。</p>
<p>假设神经网络中含有下列参数，$W^{[1]}$和$b^{[1]}$……$W^{[l]}$和$b^{[l]}$，为了执行梯度检验，把矩阵$W$转换成一个向量做连接运算，得到一个巨型向量$\theta$。代价函数$J$是所有$W$和$b$的函数，即$\theta$的代价函数$J(\theta)$。同样，把$dW^{[1]}$和${db}^{[1]}$……${dW}^{[l]}$和${db}^{[l]}$转换成一个新的向量$d\theta$，它与$\theta$具有相同维度。</p>
<p>然后循环对每个$\theta$组成元素计算$d\theta_{\text{approx}}[i]$的值，使用双边误差（导数的定义），也就是<br>$d\theta_{\text{approx}}[i] = \frac{J( \theta_{1},\theta_{2},\ldots\theta_{i} + \varepsilon,\ldots) - J( \theta_{1},\theta_{2},\ldots\theta_{i} - \varepsilon,\ldots)}{2\varepsilon}$</p>
<p>验证是否正确：<br>检查$\frac{||d\theta_{\text{approx}} -d\theta||<em>2}{||d\theta</em>{\text{approx} }||_2 + {||d\theta||}<em>2}$ 值大小。若得到的值为$10^{-7}$或更小，则说明正确；若值在$10^{-5}$范围内，也许这个值没有问题；值在$10^{-3}$范围内，就要怀疑是否有bug。<br>其中，${||d\theta</em>{\text{approx}} -d\theta||}_{2}$没有平方，它是误差平方之和，然后求平方根，得到欧式距离，然后用向量长度归一化，使用向量长度的欧几里得范数。分母只是用于预防这些向量太小或太大，分母使得这个方程式变成比率。</p>
<h3 id="梯度检验应用的注意事项"><a href="#梯度检验应用的注意事项" class="headerlink" title="梯度检验应用的注意事项"></a>梯度检验应用的注意事项</h3><ul>
<li>不要在训练中使用梯度检验，它只用于调试。因为计算过程太慢。</li>
<li>如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出bug。</li>
<li>在实施梯度检验时，如果使用正则化，记得包括正则项。</li>
<li>梯度检验不能与dropout同时使用。</li>
<li>现实中几乎不会出现的情况。当$w$和$b$接近0时，梯度下降的实施是正确的，但是在运行梯度下降时，$w$和$b$变得更大。可能只有在$w$和$b$接近0时，后向传播的实施才是正确的。但是当$W$和$b$变大时，它会变得越来越不准确。解决是在随机初始化过程中，运行梯度检验，然后再训练网络，$w$和$b$会有一段时间远离0，如果随机初始化值比较小，反复训练网络之后，再重新运行梯度检验。</li>
</ul>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/10/Coursera深度学习笔记-一-神经网络和深度学习/" rel="next" title="Coursera深度学习笔记(一) - 神经网络和深度学习">
                <i class="fa fa-chevron-left"></i> Coursera深度学习笔记(一) - 神经网络和深度学习
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/13/Coursera深度学习笔记-三-优化算法/" rel="prev" title="Coursera深度学习笔记(三) - 优化算法">
                Coursera深度学习笔记(三) - 优化算法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
            <a href="/">
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Wangsc">
            </a>    
            
              <p class="site-author-name" itemprop="name">Wangsc</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">20</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/wsczh" title="GitHub &rarr; https://github.com/wsczh" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:1998wsc@gmail.com" title="E-Mail &rarr; mailto:1998wsc@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习的一些概念"><span class="nav-number">1.</span> <span class="nav-text">机器学习的一些概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#训练集、开发集、测试集-Train-Dev-Test-sets"><span class="nav-number">1.1.</span> <span class="nav-text">训练集、开发集、测试集(Train / Dev / Test sets)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#偏差，方差（Bias-Variance）"><span class="nav-number">1.2.</span> <span class="nav-text">偏差，方差（Bias /Variance）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对神经网络进行正则化"><span class="nav-number">2.</span> <span class="nav-text">对神经网络进行正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化"><span class="nav-number">2.1.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么正则化可以降低过拟合？"><span class="nav-number">2.2.</span> <span class="nav-text">为什么正则化可以降低过拟合？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dropout-正则化"><span class="nav-number">2.3.</span> <span class="nav-text">Dropout 正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其他正则化方法"><span class="nav-number">2.4.</span> <span class="nav-text">其他正则化方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优化问题"><span class="nav-number">3.</span> <span class="nav-text">优化问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#输入数据的归一化"><span class="nav-number">3.1.</span> <span class="nav-text">输入数据的归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度消失与梯度爆炸"><span class="nav-number">3.2.</span> <span class="nav-text">梯度消失与梯度爆炸</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#神经网络的权重初始化"><span class="nav-number">3.3.</span> <span class="nav-text">神经网络的权重初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度检验"><span class="nav-number">3.4.</span> <span class="nav-text">梯度检验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度检验应用的注意事项"><span class="nav-number">3.5.</span> <span class="nav-text">梯度检验应用的注意事项</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wangsc</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.0.1</div>




        




  <script>
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=66300625";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>





        
      </div>
    </footer>

    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=7.0.1"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  
  <script src="/js/src/js.cookie.js?v=7.0.1"></script>
  <script src="/js/src/scroll-cookie.js?v=7.0.1"></script>


  

  

  


  


  




  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>


  

  

  

  

  

  

  

  

</body>
</html>
